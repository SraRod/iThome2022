version: "3.7"

services:
  triton-srv:
    container_name: triton-srv
    image: nvcr.io/nvidia/tritonserver:22.09-py3-min
    shm_size: '32GB'
    command:
      - tritonserver
      - --model-repository=/models
      - --log-verbose=1
      - --model-control-mode=explicit
      - --load-model=chestmnist
    volumes:
      - deploy:/models
    ports:
      - 8000:8000
      - 8001:8001